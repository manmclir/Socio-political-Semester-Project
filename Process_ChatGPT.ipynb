{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f13a03-9ce7-4ecc-89e3-850c0ae911be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afda86c-da45-4e90-ba19-e4044f34fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_l(df, word_list):\n",
    "    # Constructing the dynamic condition based on the list of words\n",
    "    condition = df['Text'].apply(lambda x: all(re.search(re.escape(word), x, re.IGNORECASE) for word in word_list))\n",
    "\n",
    "    # Applying the condition to filter the DataFrame\n",
    "    filtered_df = df[condition]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccd6a65-8f8a-4909-bf76-a4292685b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Characters to check for\n",
    "    punctuation_chars = [',', '\"', \"'\"]\n",
    "\n",
    "    # Iterate through each character in the text\n",
    "    processed_text = \"\"\n",
    "    for char in text:\n",
    "        # Add spaces around specified punctuation characters\n",
    "        if char in punctuation_chars:\n",
    "            processed_text += f' \\{char} '\n",
    "        else:\n",
    "            processed_text += char\n",
    "    text = processed_text\n",
    "    start_index = 0\n",
    "    end_index = len(text)\n",
    "\n",
    "    # Find the index of the first letter, <, or >\n",
    "    for i, char in enumerate(text):\n",
    "        if char.isalpha() or char == '<' or char == '>'or text[i] == '.':\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    # Find the index of the last letter, <, or >\n",
    "    for i in range(len(text) - 1, -1, -1):\n",
    "        if text[i].isalpha() or text[i] == '<' or text[i] == '>'or text[i] == '.':\n",
    "            end_index = i + 1\n",
    "            break\n",
    "\n",
    "    # Extract the substring between the first and last letters\n",
    "    result = text[start_index:end_index].strip()\n",
    "\n",
    "    result += '.'\n",
    "    result = \"['{}']\".format(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d765d60-56c1-4911-b139-39cf04f783d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrapping(text):\n",
    "    if isinstance(text, str) and text.startswith(\"['\") and text.endswith(\"']\"):\n",
    "        return text[2:-2]  # Remove the first two and last two characters\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edcdd517-3715-43f3-a549-8cb008747f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CNC_synth_copy2.csv')\n",
    "df['Text'] = df['Text'].apply(lambda x: process_text(x))\n",
    "df_o = pd.read_csv('CausalNewsCorpus/data/V2/train_subtask2_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e030c12-8359-487a-b070-39f1b3e7e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = ['<ARG0>','<ARG1>','<SIG0>','</ARG0>','</ARG1>','</SIG0>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c005618-a8e4-4f10-a624-18a90b62c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_ff = filter_dataframe_l(df, filter_list)\n",
    "df_ff = df_ff[~df_ff['Text'].str.contains('</ARG0><SIG0>')].copy()\n",
    "df_ff = df_ff[~df_ff['Text'].str.contains('</ARG0></SIG0>')].copy()\n",
    "df_ff = df_ff[~df_ff['Text'].str.contains('</ARG1><SIG0>')].copy()\n",
    "# Adding a new column 'sent_id' starting from 10000 and incrementing by 1\n",
    "df_ff['sent_id'] = range(10000, 10000 + len(df_ff))\n",
    "\n",
    "# Adding a new column 'corpus' with constant value 'cnc'\n",
    "df_ff['corpus'] = 'cnc'\n",
    "\n",
    "# Adding a new column 'eg_id' with constant value 0\n",
    "df_ff['eg_id'] = 0\n",
    "\n",
    "# Adding a new column 'doc_id' with values 'train_1000_10000' where 'train_' is constant, and the other two values are incremented by 1\n",
    "df_ff['doc_id'] = [f'train_{i}_{j}' for i, j in zip(range(1000, 1000 + len(df_ff)), range(10000, 10000 + len(df_ff)))]\n",
    "\n",
    "# Adding a new column 'index' with values based on variables i, j, k\n",
    "df_ff['index'] = [f'cnc_train_{i}_{j}_{k}_10' for i, j, k in zip(range(100, 100 + len(df_ff)), range(1000, 1000 + len(df_ff)), range(10000, 10000 + len(df_ff)))]\n",
    "df_ff.rename(columns={'Text': 'causal_text_w_pairs'}, inplace=True)\n",
    "df_ff2 = df_ff\n",
    "df_ff2['text'] = df_ff2['causal_text_w_pairs'].apply(lambda x: re.sub(r'<(/?ARG[01]|/?SIG0)>', '', x))\n",
    "\n",
    "df_ff2['num_rs'] = 1\n",
    "df_ff2 = df_ff2[['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text', 'causal_text_w_pairs', 'num_rs']]\n",
    "df_ff2['text'] = df_ff2['text'].apply(lambda x: process_text(x))\n",
    "df_ff2['text'] = df_ff2['text'].apply(remove_wrapping)\n",
    "df_ff2['text'] = df_ff2['text'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('> ', '>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('><', '> <', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('</SIG0>', '</SIG0> ', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG0> </SIG0>', '</ARG0> </SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG0> <SIG0>', '</ARG0> <SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG1> <SIG0>', '</ARG1> <SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('<ARG0> <SIG0>', '<ARG0><SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('<ARG1> <SIG0>', '<ARG1><SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG0> <ARG1><SIG0>', '</ARG0> <ARG1><SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG0> <ARG1></SIG0>', '</ARG0> <ARG1></SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG0> </ARG1></SIG0>', '</ARG0> </ARG1></SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('</ARG0>', '</ARG0> ', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('</ARG1>', '</ARG1> ', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace('</ARG1> <SIG0>', '</ARG1><SIG0>', regex=True)\n",
    "df_ff2['causal_text_w_pairs'] = df_ff2['causal_text_w_pairs'].str.replace(' </ARG1> <ARG0><SIG0>', '</ARG1> <ARG0><SIG0>', regex=True)\n",
    "print(len(df_ff2))\n",
    "result_df2 = pd.concat([df_o, df_ff2], ignore_index=True)\n",
    "#result_df2.to_csv('CNC_chatgpt+orig_output_no_space6.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c584f8-c144-4186-94de-ef83deb34826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
